/**
 * Migration Studio Service
 * Handles experiment management, assignment logic, and guardrail evaluation
 */

import { Pool, PoolClient } from 'pg';
import { createHash, randomBytes, randomUUID } from 'crypto';
import {
  MigrationExperiment,
  MigrationMapping,
  CreateExperimentRequest,
  UpdateExperimentRequest,
  ActivateExperimentRequest,
  ExperimentArm,
  Guardrails,
  MigrationImport,
  EvaluateGuardrailsResult,
  ExperimentMode,
  MappingStatus,
  MappingConfidence,
  MigrationImportSummary,
  MigrationSignedComparison,
} from '../types/migration';
import { AppError } from '../middleware/errorHandler';
import logger from '../utils/logger';
import { parseMigrationCsv } from '../utils/migrationCsvParser';
import {
  fetchAppLovinSetup,
  fetchIronSourceSetup,
  NormalizedMappingRow,
} from './migrationImportConnectors';
import { generateSignedComparison } from './migrationComparisonSigner';

const DEFAULT_GUARDRAILS: Guardrails = {
  latency_budget_ms: 500,
  revenue_floor_percent: -10,
  max_error_rate_percent: 5,
  min_impressions: 1000,
};

const ADAPTER_SUGGESTIONS: Record<string, { id: string; name: string; confidence: MappingConfidence }> = {
  applovin: {
    id: 'apex_adapter_applovin_max_v1',
    name: 'Apex · AppLovin MAX',
    confidence: 'high',
  },
  max: {
    id: 'apex_adapter_applovin_max_v1',
    name: 'Apex · AppLovin MAX',
    confidence: 'high',
  },
  ironsource: {
    id: 'apex_adapter_ironsource_v1',
    name: 'Apex · ironSource',
    confidence: 'high',
  },
  unity: {
    id: 'apex_adapter_unity_ads_v1',
    name: 'Apex · Unity Ads',
    confidence: 'medium',
  },
};

function resolveAdapterSuggestion(network: string | undefined) {
  if (!network) return null;
  const normalized = network.toLowerCase();
  const direct = ADAPTER_SUGGESTIONS[normalized];
  if (direct) return direct;

  const entry = Object.entries(ADAPTER_SUGGESTIONS).find(([alias]) => normalized.includes(alias));
  return entry ? entry[1] : null;
}

export type FeatureFlagSource = 'placement' | 'app' | 'publisher' | 'default';

export interface EffectiveFeatureFlags {
  shadowEnabled: boolean;
  mirroringEnabled: boolean;
  source: FeatureFlagSource;
}

export class MigrationStudioService {
  constructor(private pool: Pool) {}

  private async validatePlacementOwnership(client: PoolClient, placementId: string, publisherId: string): Promise<void> {
    const placementCheck = await client.query(
      `SELECT p.id FROM placements p
         JOIN apps a ON p.app_id = a.id
       WHERE p.id = $1 AND a.publisher_id = $2`,
      [placementId, publisherId]
    );

    if (placementCheck.rows.length === 0) {
      throw new AppError('Placement not found or access denied', 404);
    }
  }

  /**
   * Create a new migration experiment
   */
  async createExperiment(
    publisherId: string,
    userId: string,
    data: CreateExperimentRequest
  ): Promise<MigrationExperiment> {
    const client = await this.pool.connect();
    
    try {
      await client.query('BEGIN');

      // Validate placement exists and belongs to publisher
      if (data.placement_id) {
        await this.validatePlacementOwnership(client, data.placement_id, publisherId);
      }

      const guardrails = { ...DEFAULT_GUARDRAILS, ...(data.guardrails ?? {}) };

      // Create experiment
      const result = await client.query(
        `INSERT INTO migration_experiments (
          publisher_id, name, description, app_id, placement_id, 
          objective, seed, guardrails, created_by
        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
        RETURNING *`,
        [
          publisherId,
          data.name,
          data.description || null,
          data.app_id || null,
          data.placement_id || null,
          data.objective || 'revenue_comparison',
          data.seed || randomUUID(),
          JSON.stringify(guardrails),
          userId,
        ]
      );

      const experiment = result.rows[0];

      // Audit log
      await client.query(
        `INSERT INTO migration_audit (
          experiment_id, user_id, action, resource_type, resource_id, new_value
        ) VALUES ($1, $2, $3, $4, $5, $6)`,
        [
          experiment.id,
          userId,
          'create',
          'experiment',
          experiment.id,
          JSON.stringify(experiment),
        ]
      );

      await client.query('COMMIT');
      
      logger.info('Migration experiment created', { experimentId: experiment.id, publisherId });
      return this.mapExperiment(experiment);
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  }

  private parseImportSummary(value: any): MigrationImportSummary {
    const base: MigrationImportSummary = {
      total_mappings: 0,
      status_breakdown: {
        pending: 0,
        confirmed: 0,
        skipped: 0,
        conflict: 0,
      },
      confidence_breakdown: {
        high: 0,
        medium: 0,
        low: 0,
      },
      unique_networks: 0,
    };

    if (!value) {
      return base;
    }

    let parsed = value;
    if (typeof value === 'string') {
      try {
        parsed = JSON.parse(value);
      } catch {
        return base;
      }
    }

    return {
      total_mappings: typeof parsed.total_mappings === 'number' ? parsed.total_mappings : base.total_mappings,
      status_breakdown: {
        pending: parsed.status_breakdown?.pending ?? base.status_breakdown.pending,
        confirmed: parsed.status_breakdown?.confirmed ?? base.status_breakdown.confirmed,
        skipped: parsed.status_breakdown?.skipped ?? base.status_breakdown.skipped,
        conflict: parsed.status_breakdown?.conflict ?? base.status_breakdown.conflict,
      },
      confidence_breakdown: {
        high: parsed.confidence_breakdown?.high ?? base.confidence_breakdown.high,
        medium: parsed.confidence_breakdown?.medium ?? base.confidence_breakdown.medium,
        low: parsed.confidence_breakdown?.low ?? base.confidence_breakdown.low,
      },
      unique_networks: typeof parsed.unique_networks === 'number' ? parsed.unique_networks : base.unique_networks,
    };
  }

  private mapImport(row: any): MigrationImport {
    return {
      id: row.id,
      publisher_id: row.publisher_id,
      experiment_id: row.experiment_id,
      placement_id: row.placement_id,
      source: row.source,
      status: row.status,
      summary: this.parseImportSummary(row.summary),
      error_message: row.error_message,
      created_by: row.created_by,
      created_at: row.created_at,
      updated_at: row.updated_at,
      completed_at: row.completed_at,
    };
  }

  private mapMapping(row: any): MigrationMapping {
    return {
      id: row.id,
      experiment_id: row.experiment_id,
      incumbent_network: row.incumbent_network,
      incumbent_instance_id: row.incumbent_instance_id,
      incumbent_instance_name: row.incumbent_instance_name,
      incumbent_waterfall_position: row.incumbent_waterfall_position,
      incumbent_ecpm_cents: row.incumbent_ecpm_cents,
      our_adapter_id: row.our_adapter_id,
      our_adapter_name: row.our_adapter_name,
      mapping_status: (row.mapping_status || 'pending') as MappingStatus,
      mapping_confidence: (row.mapping_confidence || 'medium') as MappingConfidence,
      conflict_reason: row.conflict_reason,
      resolved_by: row.resolved_by,
      resolved_at: row.resolved_at,
      created_at: row.created_at,
      updated_at: row.updated_at,
    };
  }

  private summarizeMappings(mappings: MigrationMapping[]): MigrationImportSummary {
    const statusBreakdown: Record<MappingStatus, number> = {
      pending: 0,
      confirmed: 0,
      skipped: 0,
      conflict: 0,
    };

    const confidenceBreakdown: Record<MappingConfidence, number> = {
      high: 0,
      medium: 0,
      low: 0,
    };

    const networks = new Set<string>();

    for (const mapping of mappings) {
      const status = (mapping.mapping_status || 'pending') as MappingStatus;
      statusBreakdown[status] = (statusBreakdown[status] ?? 0) + 1;

      const confidence = (mapping.mapping_confidence || 'medium') as MappingConfidence;
      confidenceBreakdown[confidence] = (confidenceBreakdown[confidence] ?? 0) + 1;

      if (mapping.incumbent_network) {
        networks.add(mapping.incumbent_network);
      }
    }

    return {
      total_mappings: mappings.length,
      status_breakdown: statusBreakdown,
      confidence_breakdown: confidenceBreakdown,
      unique_networks: networks.size,
    };
  }

  /**
   * Get experiment by ID (with publisher scope check)
   */
  async getExperiment(experimentId: string, publisherId: string): Promise<MigrationExperiment> {
    const result = await this.pool.query(
      `SELECT * FROM migration_experiments WHERE id = $1 AND publisher_id = $2`,
      [experimentId, publisherId]
    );

    if (result.rows.length === 0) {
      throw new AppError('Experiment not found', 404);
    }

    return this.mapExperiment(result.rows[0]);
  }

  /**
   * List experiments for a publisher
   */
  async listExperiments(
    publisherId: string,
    filters?: { status?: string; placement_id?: string }
  ): Promise<MigrationExperiment[]> {
    let query = 'SELECT * FROM migration_experiments WHERE publisher_id = $1';
    const params: any[] = [publisherId];

    if (filters?.status) {
      params.push(filters.status);
      query += ` AND status = $${params.length}`;
    }

    if (filters?.placement_id) {
      params.push(filters.placement_id);
      query += ` AND placement_id = $${params.length}`;
    }

    query += ' ORDER BY created_at DESC';

    const result = await this.pool.query(query, params);
    return result.rows.map(row => this.mapExperiment(row));
  }

  /**
   * Create or update an import job and draft mappings
   */
  async createImport(options: {
    publisherId: string;
    userId: string;
    placementId: string;
    experimentId?: string;
    source: 'csv' | 'ironSource' | 'applovin';
    fileBuffer?: Buffer;
    credentials?: { api_key: string; account_id: string };
  }): Promise<{
    import: MigrationImport;
    mappings: MigrationMapping[];
    experiment: MigrationExperiment;
    summary: MigrationImportSummary;
    signedComparison: MigrationSignedComparison;
  }> {
    const client = await this.pool.connect();

    try {
      await client.query('BEGIN');

      await this.validatePlacementOwnership(client, options.placementId, options.publisherId);

      let experimentId = options.experimentId;
      let experimentRow;

      if (experimentId) {
        const existing = await client.query(
          `SELECT * FROM migration_experiments WHERE id = $1 AND publisher_id = $2`,
          [experimentId, options.publisherId]
        );

        if (existing.rows.length === 0) {
          throw new AppError('Experiment not found', 404);
        }

        experimentRow = existing.rows[0];
      } else {
        const insertExp = await client.query(
          `INSERT INTO migration_experiments (
            publisher_id, name, description, placement_id, objective, seed, mirror_percent, status, guardrails, created_by
          ) VALUES ($1, $2, $3, $4, $5, $6, 0, 'draft', $7, $8)
          RETURNING *`,
          [
            options.publisherId,
            `Migration import ${new Date().toISOString()}`,
            'Draft created from import wizard',
            options.placementId,
            'revenue_comparison',
            randomBytes(8).toString('hex'),
            JSON.stringify(DEFAULT_GUARDRAILS),
            options.userId,
          ]
        );

        experimentRow = insertExp.rows[0];
        experimentId = experimentRow.id;

        await client.query(
          `INSERT INTO migration_audit (
            experiment_id, user_id, action, resource_type, resource_id, new_value
          ) VALUES ($1, $2, $3, $4, $5, $6)`,
          [
            experimentId,
            options.userId,
            'create_import_experiment',
            'experiment',
            experimentId,
            JSON.stringify(experimentRow),
          ]
        );
      }

      let normalized: NormalizedMappingRow[] = [];

      if (options.source === 'csv') {
        if (!options.fileBuffer) {
          throw new AppError('CSV file required for import', 400);
        }
        try {
          normalized = parseMigrationCsv(options.fileBuffer);
        } catch (err) {
          throw new AppError((err as Error).message || 'Unable to parse CSV', 400);
        }
      } else if (options.source === 'ironSource') {
        if (!options.credentials) {
          throw new AppError('ironSource credentials required', 400);
        }
        try {
          normalized = await fetchIronSourceSetup(options.credentials);
        } catch (err) {
          throw new AppError((err as Error).message, 400);
        }
      } else if (options.source === 'applovin') {
        if (!options.credentials) {
          throw new AppError('AppLovin credentials required', 400);
        }
        try {
          normalized = await fetchAppLovinSetup(options.credentials);
        } catch (err) {
          throw new AppError((err as Error).message, 400);
        }
      } else {
        throw new AppError('Unsupported import source', 400);
      }

      if (normalized.length === 0) {
        throw new AppError('No mappings detected in import', 400);
      }

      const importResult = await client.query(
        `INSERT INTO migration_imports (
          publisher_id, experiment_id, placement_id, source, status, summary, created_by
        ) VALUES ($1, $2, $3, $4, 'pending_review', '{}'::jsonb, $5)
        RETURNING *`,
        [options.publisherId, experimentId, options.placementId, options.source, options.userId]
      );

      const insertedMappings: MigrationMapping[] = [];

      for (const row of normalized) {
        const suggestion = resolveAdapterSuggestion(row.network);
        const adapterId = suggestion?.id ?? null;
        const adapterName = suggestion?.name ?? null;
        const mappingStatus: MappingStatus = suggestion ? 'confirmed' : 'pending';
        const mappingConfidence: MappingConfidence = suggestion?.confidence ?? row.confidence ?? 'medium';

        const result = await client.query(
          `INSERT INTO migration_mappings (
            experiment_id,
            incumbent_network,
            incumbent_instance_id,
            incumbent_instance_name,
            incumbent_waterfall_position,
            incumbent_ecpm_cents,
            mapping_status,
            mapping_confidence,
            our_adapter_id,
            our_adapter_name
          ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
          ON CONFLICT (experiment_id, incumbent_instance_id)
          DO UPDATE SET
            incumbent_network = EXCLUDED.incumbent_network,
            incumbent_instance_name = EXCLUDED.incumbent_instance_name,
            incumbent_waterfall_position = EXCLUDED.incumbent_waterfall_position,
            incumbent_ecpm_cents = EXCLUDED.incumbent_ecpm_cents,
            mapping_confidence = EXCLUDED.mapping_confidence,
            our_adapter_id = COALESCE(EXCLUDED.our_adapter_id, migration_mappings.our_adapter_id),
            our_adapter_name = COALESCE(EXCLUDED.our_adapter_name, migration_mappings.our_adapter_name),
            mapping_status = CASE
              WHEN migration_mappings.mapping_status IN ('confirmed','skipped') THEN migration_mappings.mapping_status
              ELSE EXCLUDED.mapping_status
            END,
            updated_at = NOW()
          RETURNING *`,
          [
            experimentId,
            row.network,
            row.instanceId,
            row.instanceName || null,
            row.waterfallPosition ?? null,
            row.ecpmCents ?? null,
            mappingStatus,
            mappingConfidence,
            adapterId,
            adapterName,
          ]
        );

        insertedMappings.push(this.mapMapping(result.rows[0]));
      }

      const summary = this.summarizeMappings(insertedMappings);

      const updatedImport = await client.query(
        `UPDATE migration_imports
         SET summary = $1, updated_at = NOW()
         WHERE id = $2
         RETURNING *`,
        [JSON.stringify(summary), importResult.rows[0].id]
      );

      const experiment = this.mapExperiment(experimentRow);
      const importJob = this.mapImport(updatedImport.rows[0]);

      await client.query('COMMIT');

      const signedComparison = generateSignedComparison(insertedMappings);

      return {
        import: importJob,
        mappings: insertedMappings,
        experiment,
        summary,
        signedComparison,
      };
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  }

  async updateMapping(
    mappingId: string,
    publisherId: string,
    userId: string,
    options: {
      ourAdapterId?: string;
      status?: MappingStatus;
      notes?: string;
    }
  ): Promise<{ mapping: MigrationMapping; summary: MigrationImportSummary }>
  {
    const client = await this.pool.connect();

    try {
      await client.query('BEGIN');

      const mappingResult = await client.query(
        `SELECT m.*
         FROM migration_mappings m
         JOIN migration_experiments e ON m.experiment_id = e.id
         WHERE m.id = $1 AND e.publisher_id = $2
         FOR UPDATE`,
        [mappingId, publisherId]
      );

      if (mappingResult.rows.length === 0) {
        throw new AppError('Mapping not found', 404);
      }

      const currentRow = mappingResult.rows[0];
      const experimentId = currentRow.experiment_id;

      const adapterId = options.ourAdapterId?.trim() || null;

      const allowedStatuses: MappingStatus[] = ['pending', 'confirmed', 'skipped', 'conflict'];
      let status: MappingStatus;
      if (options.status) {
        if (!allowedStatuses.includes(options.status)) {
          throw new AppError('Invalid mapping status', 400);
        }
        status = options.status;
      } else {
        status = adapterId ? 'confirmed' : 'pending';
      }

      let conflictReason: string | null = null;
      if (status === 'conflict') {
        conflictReason = options.notes?.trim() || currentRow.conflict_reason || 'Requires review';
      } else if (options.notes !== undefined) {
        conflictReason = options.notes ? options.notes.trim() : null;
      }

      const updated = await client.query(
        `UPDATE migration_mappings
         SET our_adapter_id = $1,
             our_adapter_name = $2,
             mapping_status = $3,
             conflict_reason = $4,
             resolved_by = CASE WHEN $3 IN ('confirmed','skipped') THEN $5 ELSE NULL END,
             resolved_at = CASE WHEN $3 IN ('confirmed','skipped') THEN NOW() ELSE NULL END,
             updated_at = NOW()
         WHERE id = $6
         RETURNING *`,
        [adapterId, adapterId, status, conflictReason, userId, mappingId]
      );

      const { rows: mappingRows } = await client.query(
        `SELECT * FROM migration_mappings WHERE experiment_id = $1`,
        [experimentId]
      );

      const mappedRows = mappingRows.map(row => this.mapMapping(row));
      const summary = this.summarizeMappings(mappedRows);

      const latestImport = await client.query<{ id: string }>(
        `SELECT id FROM migration_imports
         WHERE experiment_id = $1
         ORDER BY created_at DESC
         LIMIT 1`,
        [experimentId]
      );

      if (latestImport.rows[0]) {
        await client.query(
          `UPDATE migration_imports
           SET summary = $1::jsonb,
               updated_at = NOW()
           WHERE id = $2`,
          [JSON.stringify(summary), latestImport.rows[0].id]
        );
      }

      await client.query(
        `INSERT INTO migration_audit (
           experiment_id, user_id, action, resource_type, resource_id, new_value
         ) VALUES ($1, $2, $3, $4, $5, $6)`,
        [
          experimentId,
          userId,
          'update_mapping',
          'mapping',
          mappingId,
          JSON.stringify(updated.rows[0]),
        ]
      );

      await client.query('COMMIT');

      return {
        mapping: this.mapMapping(updated.rows[0]),
        summary,
      };
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  }

  async finalizeImport(
    importId: string,
    publisherId: string,
    userId: string
  ): Promise<{
    import: MigrationImport;
    mappings: MigrationMapping[];
    summary: MigrationImportSummary;
    signedComparison: MigrationSignedComparison;
  }> {
    const client = await this.pool.connect();

    try {
      await client.query('BEGIN');

      const importResult = await client.query(
        `SELECT * FROM migration_imports
         WHERE id = $1 AND publisher_id = $2
         FOR UPDATE`,
        [importId, publisherId]
      );

      if (importResult.rows.length === 0) {
        throw new AppError('Import not found', 404);
      }

      const importRow = importResult.rows[0];

      if (!importRow.experiment_id) {
        throw new AppError('Import is not associated with an experiment', 400);
      }

      if (importRow.status !== 'pending_review' && importRow.status !== 'draft') {
        throw new AppError('Import already finalized', 400);
      }

      const { rows: mappingRows } = await client.query(
        `SELECT * FROM migration_mappings WHERE experiment_id = $1`,
        [importRow.experiment_id]
      );

      if (mappingRows.length === 0) {
        throw new AppError('No mappings found for experiment', 400);
      }

      const mappedRows = mappingRows.map(row => this.mapMapping(row));
      const unresolved = mappedRows.filter(mapping => mapping.mapping_status === 'pending');
      if (unresolved.length > 0) {
        throw new AppError(`Resolve ${unresolved.length} pending mappings before finalizing`, 400);
      }

      const conflicts = mappedRows.filter(mapping => mapping.mapping_status === 'conflict');
      if (conflicts.length > 0) {
        throw new AppError('Resolve conflicts before finalizing import', 400);
      }

      const summary = this.summarizeMappings(mappedRows);

      const updatedImport = await client.query(
        `UPDATE migration_imports
         SET status = 'completed',
             summary = $1::jsonb,
             completed_at = NOW(),
             updated_at = NOW()
         WHERE id = $2
         RETURNING *`,
        [JSON.stringify(summary), importId]
      );

      await client.query(
        `UPDATE migration_experiments
         SET mode = 'shadow',
             updated_at = NOW(),
             last_guardrail_check = NOW()
         WHERE id = $1`,
        [importRow.experiment_id]
      );

      await client.query(
        `INSERT INTO migration_audit (
           experiment_id, user_id, action, resource_type, resource_id, new_value
         ) VALUES ($1, $2, $3, $4, $5, $6)`,
        [
          importRow.experiment_id,
          userId,
          'finalize_import',
          'import',
          importId,
          JSON.stringify(updatedImport.rows[0]),
        ]
      );

      await client.query('COMMIT');

      const signedComparison = generateSignedComparison(mappedRows);

      return {
        import: this.mapImport(updatedImport.rows[0]),
        mappings: mappedRows,
        summary,
        signedComparison,
      };
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  }

  /**
   * Update experiment (draft/paused only)
   */
  async updateExperiment(
    experimentId: string,
    publisherId: string,
    userId: string,
    data: UpdateExperimentRequest
  ): Promise<MigrationExperiment> {
    const client = await this.pool.connect();

    try {
      await client.query('BEGIN');

      // Get existing experiment
      const existing = await client.query(
        `SELECT * FROM migration_experiments WHERE id = $1 AND publisher_id = $2`,
        [experimentId, publisherId]
      );

      if (existing.rows.length === 0) {
        throw new AppError('Experiment not found', 404);
      }

      const exp = existing.rows[0];

      // Only allow updates to draft or paused experiments
      if (!['draft', 'paused'].includes(exp.status)) {
        throw new AppError('Cannot update active or completed experiment', 400);
      }

      // Build update query
      const updates: string[] = [];
      const params: any[] = [];
      let paramIndex = 1;

      if (data.name !== undefined) {
        updates.push(`name = $${paramIndex++}`);
        params.push(data.name);
      }

      if (data.description !== undefined) {
        updates.push(`description = $${paramIndex++}`);
        params.push(data.description);
      }

      if (data.mirror_percent !== undefined) {
        if (data.mirror_percent < 0 || data.mirror_percent > 20) {
          throw new AppError('mirror_percent must be between 0 and 20', 400);
        }
        updates.push(`mirror_percent = $${paramIndex++}`);
        params.push(data.mirror_percent);
      }

      if (data.guardrails !== undefined) {
        const mergedGuardrails = { ...exp.guardrails, ...data.guardrails };
        updates.push(`guardrails = $${paramIndex++}`);
        params.push(JSON.stringify(mergedGuardrails));
      }

      if (updates.length === 0) {
        throw new AppError('No updates provided', 400);
      }

      updates.push(`updated_at = NOW()`);
      params.push(experimentId, publisherId);

      const result = await client.query(
        `UPDATE migration_experiments 
         SET ${updates.join(', ')}
         WHERE id = $${paramIndex++} AND publisher_id = $${paramIndex++}
         RETURNING *`,
        params
      );

      // Audit log
      await client.query(
        `INSERT INTO migration_audit (
          experiment_id, user_id, action, resource_type, resource_id, old_value, new_value
        ) VALUES ($1, $2, $3, $4, $5, $6, $7)`,
        [
          experimentId,
          userId,
          'update',
          'experiment',
          experimentId,
          JSON.stringify(exp),
          JSON.stringify(result.rows[0]),
        ]
      );

      await client.query('COMMIT');
      
      return this.mapExperiment(result.rows[0]);
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  }

  /**
   * Activate experiment (start mirroring traffic)
   */
  async activateExperiment(
    experimentId: string,
    publisherId: string,
    userId: string,
    data: ActivateExperimentRequest
  ): Promise<MigrationExperiment> {
    const client = await this.pool.connect();

    try {
      await client.query('BEGIN');

      const result = await client.query(
        `UPDATE migration_experiments
         SET status = 'active',
             mode = 'mirroring',
             mirror_percent = $1,
             activated_at = NOW(),
             last_guardrail_check = NOW(),
             updated_at = NOW()
         WHERE id = $2 AND publisher_id = $3 AND status IN ('draft', 'paused')
         RETURNING *`,
        [data.mirror_percent, experimentId, publisherId]
      );

      if (result.rows.length === 0) {
        throw new AppError('Experiment not found or cannot be activated', 404);
      }

      // Log activation event
      await client.query(
        `INSERT INTO migration_events (experiment_id, event_type, reason, triggered_by)
         VALUES ($1, $2, $3, $4)`,
        [experimentId, 'activation', `Activated with ${data.mirror_percent}% mirror`, userId]
      );

      // Audit log
      await client.query(
        `INSERT INTO migration_audit (experiment_id, user_id, action, resource_type, resource_id)
         VALUES ($1, $2, $3, $4, $5)`,
        [experimentId, userId, 'activate', 'experiment', experimentId]
      );

      await client.query('COMMIT');

      logger.info('Experiment activated', { experimentId, mirrorPercent: data.mirror_percent });
      return this.mapExperiment(result.rows[0]);
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  }

  /**
   * Pause experiment (stop traffic mirroring)
   */
  async pauseExperiment(
    experimentId: string,
    publisherId: string,
    userId: string,
    reason?: string
  ): Promise<MigrationExperiment> {
    const client = await this.pool.connect();

    try {
      await client.query('BEGIN');

      const result = await client.query(
        `UPDATE migration_experiments
         SET status = 'paused',
             mode = 'shadow',
             paused_at = NOW(),
             updated_at = NOW()
         WHERE id = $1 AND publisher_id = $2 AND status = 'active'
         RETURNING *`,
        [experimentId, publisherId]
      );

      if (result.rows.length === 0) {
        throw new AppError('Experiment not found or not active', 404);
      }

      // Log deactivation event
      await client.query(
        `INSERT INTO migration_events (experiment_id, event_type, reason, triggered_by)
         VALUES ($1, $2, $3, $4)`,
        [experimentId, 'deactivation', reason || 'Manual pause', userId]
      );

      await client.query('COMMIT');

      logger.info('Experiment paused', { experimentId, reason });
      return this.mapExperiment(result.rows[0]);
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  }

  /**
   * Deterministic assignment: hash(user, placement, seed) < mirror_percent → test
   */
  async getEffectiveFeatureFlags(
    publisherId: string,
    appId?: string | null,
    placementId?: string | null
  ): Promise<EffectiveFeatureFlags> {
    const { rows } = await this.pool.query(
      `SELECT
         placement_id::text AS placement_id,
         app_id::text AS app_id,
         shadow_enabled,
         mirroring_enabled
       FROM migration_feature_flags
       WHERE publisher_id = $1
         AND (app_id IS NULL OR app_id = $2::uuid)
         AND (placement_id IS NULL OR placement_id = $3::uuid)
       ORDER BY updated_at DESC`,
      [publisherId, appId ?? null, placementId ?? null]
    );

    if (!rows || rows.length === 0) {
      return { shadowEnabled: false, mirroringEnabled: false, source: 'default' };
    }

    const placementRow = placementId
      ? rows.find((row: any) => row.placement_id && row.placement_id === placementId)
      : undefined;

    if (placementRow) {
      return {
        shadowEnabled: Boolean(placementRow.shadow_enabled),
        mirroringEnabled: Boolean(placementRow.mirroring_enabled),
        source: 'placement',
      };
    }

    const appRow = appId
      ? rows.find((row: any) => !row.placement_id && row.app_id && row.app_id === appId)
      : undefined;

    if (appRow) {
      return {
        shadowEnabled: Boolean(appRow.shadow_enabled),
        mirroringEnabled: Boolean(appRow.mirroring_enabled),
        source: 'app',
      };
    }

    const publisherRow = rows.find((row: any) => !row.placement_id && !row.app_id);
    if (publisherRow) {
      return {
        shadowEnabled: Boolean(publisherRow.shadow_enabled),
        mirroringEnabled: Boolean(publisherRow.mirroring_enabled),
        source: 'publisher',
      };
    }

    return { shadowEnabled: false, mirroringEnabled: false, source: 'default' };
  }

  /**
   * Deterministic assignment: hash(user, placement, seed) < mirror_percent → test
   */
  assignArm(
    userIdentifier: string,
    placementId: string,
    seed: string,
    mirrorPercent: number
  ): ExperimentArm {
    const hash = createHash('sha256')
      .update(`${userIdentifier}:${placementId}:${seed}`)
      .digest('hex');

    // Take first 8 hex chars and convert to percentage (0-100)
    const hashInt = parseInt(hash.substring(0, 8), 16);
    const percentage = (hashInt % 100) / 100; // 0.00 to 0.99

    return percentage < (mirrorPercent / 100) ? 'test' : 'control';
  }

  /**
   * Log assignment decision
   */
  async logAssignment(
    experimentId: string,
    arm: ExperimentArm,
    userIdentifier: string,
    placementId: string,
    metadata?: Record<string, any>
  ): Promise<void> {
    // Hash user identifier for privacy
    const hashedUser = createHash('sha256').update(userIdentifier).digest('hex');

    await this.pool.query(
      `INSERT INTO migration_events (
        experiment_id, event_type, arm, user_identifier, placement_id, event_data
      ) VALUES ($1, $2, $3, $4, $5, $6)`,
      [
        experimentId,
        'assignment',
        arm,
        hashedUser,
        placementId,
        JSON.stringify(metadata || {}),
      ]
    );
  }

  /**
   * Evaluate guardrails and pause if violated
   */
  async evaluateGuardrails(
    experimentId: string,
    publisherId: string,
    triggeredBy?: string
  ): Promise<EvaluateGuardrailsResult> {
    const client = await this.pool.connect();

    try {
      await client.query('BEGIN');

      const experimentResult = await client.query(
        `SELECT * FROM migration_experiments
         WHERE id = $1 AND publisher_id = $2
         FOR UPDATE`,
        [experimentId, publisherId]
      );

      if (experimentResult.rows.length === 0) {
        throw new AppError('Experiment not found', 404);
      }

      const experimentRow = experimentResult.rows[0];
      const guardrails = this.parseGuardrails(experimentRow.guardrails);

      const snapshotsResult = await client.query(
        `SELECT arm, impressions, fills, revenue_micros, latency_p95_ms, error_rate_percent
         FROM migration_guardrail_snapshots
         WHERE experiment_id = $1 AND captured_at >= NOW() - INTERVAL '6 hours'
         ORDER BY captured_at DESC
         LIMIT 50`,
        [experimentId]
      );

      if (snapshotsResult.rows.length === 0) {
        await client.query(
          `UPDATE migration_experiments
           SET last_guardrail_check = NOW(), updated_at = NOW()
           WHERE id = $1`,
          [experimentId]
        );
        await client.query('COMMIT');
        return { shouldPause: false, violations: [] };
      }

      type Aggregation = {
        impressions: number;
        revenueMicros: number;
        latencies: number[];
        errors: number[];
      };

      const aggregate: Record<ExperimentArm, Aggregation> = {
        control: { impressions: 0, revenueMicros: 0, latencies: [], errors: [] },
        test: { impressions: 0, revenueMicros: 0, latencies: [], errors: [] },
      };

      for (const snapshot of snapshotsResult.rows) {
        const arm = snapshot.arm as ExperimentArm;
        const bucket = aggregate[arm];
        bucket.impressions += Number(snapshot.impressions || 0);
        bucket.revenueMicros += Number(snapshot.revenue_micros || 0);

        if (typeof snapshot.latency_p95_ms === 'number') {
          bucket.latencies.push(snapshot.latency_p95_ms);
        }

        if (typeof snapshot.error_rate_percent === 'number') {
          bucket.errors.push(Number(snapshot.error_rate_percent));
        }
      }

      const minImpressions = guardrails.min_impressions ?? DEFAULT_GUARDRAILS.min_impressions;
      if (aggregate.test.impressions < minImpressions) {
        await client.query(
          `UPDATE migration_experiments
           SET last_guardrail_check = NOW(), updated_at = NOW()
           WHERE id = $1`,
          [experimentId]
        );
        await client.query('COMMIT');
        return { shouldPause: false, violations: [] };
      }

      const average = (values: number[]): number | null => {
        if (values.length === 0) return null;
        return values.reduce((sum, value) => sum + value, 0) / values.length;
      };

      const maxLatency = (values: number[]): number | null => {
        if (values.length === 0) return null;
        return Math.max(...values);
      };

      const testLatency = maxLatency(aggregate.test.latencies);
      const testErrorRate = average(aggregate.test.errors);
      const controlEcpm = aggregate.control.impressions > 0
        ? (aggregate.control.revenueMicros / aggregate.control.impressions) / 1000
        : null;
      const testEcpm = aggregate.test.impressions > 0
        ? (aggregate.test.revenueMicros / aggregate.test.impressions) / 1000
        : null;

      const violations: string[] = [];

      if (guardrails.latency_budget_ms && testLatency && testLatency > guardrails.latency_budget_ms) {
        violations.push(`Latency ${testLatency}ms exceeds budget ${guardrails.latency_budget_ms}ms`);
      }

      if (guardrails.max_error_rate_percent && testErrorRate && testErrorRate > guardrails.max_error_rate_percent) {
        violations.push(`Error rate ${testErrorRate.toFixed(2)}% exceeds max ${guardrails.max_error_rate_percent}%`);
      }

      if (
        typeof guardrails.revenue_floor_percent === 'number' &&
        controlEcpm !== null &&
        controlEcpm > 0 &&
        testEcpm !== null
      ) {
        const revenueDelta = ((testEcpm - controlEcpm) / controlEcpm) * 100;
        if (revenueDelta < guardrails.revenue_floor_percent) {
          violations.push(
            `Revenue delta ${revenueDelta.toFixed(2)}% below floor ${guardrails.revenue_floor_percent}%`
          );
        }
      }

      const shouldPause = violations.length > 0;

      if (shouldPause && experimentRow.status === 'active') {
        await client.query(
          `UPDATE migration_experiments
           SET status = 'paused',
               mode = 'shadow',
               paused_at = COALESCE(paused_at, NOW()),
               last_guardrail_check = NOW(),
               updated_at = NOW()
           WHERE id = $1`,
          [experimentId]
        );

        await client.query(
          `INSERT INTO migration_events (
             experiment_id, event_type, reason, triggered_by, event_data
           ) VALUES ($1, $2, $3, $4, $5)`,
          [
            experimentId,
            violations.includes('Revenue') ? 'guardrail_kill' : 'guardrail_pause',
            violations.join('; '),
            triggeredBy || 'system',
            JSON.stringify({
              violations,
              metrics: {
                testLatency,
                testErrorRate,
                testEcpm,
                controlEcpm,
              },
            }),
          ]
        );
      } else {
        await client.query(
          `UPDATE migration_experiments
           SET last_guardrail_check = NOW(), updated_at = NOW()
           WHERE id = $1`,
          [experimentId]
        );
      }

      await client.query('COMMIT');
      return { shouldPause, violations };
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  }

  /**
   * Delete experiment (soft delete to archived)
   */
  async deleteExperiment(
    experimentId: string,
    publisherId: string,
    userId: string
  ): Promise<void> {
    const client = await this.pool.connect();

    try {
      await client.query('BEGIN');

      const result = await client.query(
        `UPDATE migration_experiments
         SET status = 'archived', updated_at = NOW()
         WHERE id = $1 AND publisher_id = $2 AND status IN ('draft', 'paused', 'completed')
         RETURNING id`,
        [experimentId, publisherId]
      );

      if (result.rows.length === 0) {
        throw new AppError('Experiment not found or cannot be deleted', 404);
      }

      // Audit log
      await client.query(
        `INSERT INTO migration_audit (experiment_id, user_id, action, resource_type, resource_id)
         VALUES ($1, $2, $3, $4, $5)`,
        [experimentId, userId, 'delete', 'experiment', experimentId]
      );

      await client.query('COMMIT');
      logger.info('Experiment archived', { experimentId });
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
  }

  private parseGuardrails(value: any): Guardrails {
    if (!value) {
      return { ...DEFAULT_GUARDRAILS };
    }

    let parsed = value;
    if (typeof value === 'string') {
      try {
        parsed = JSON.parse(value);
      } catch {
        return { ...DEFAULT_GUARDRAILS };
      }
    }

    return { ...DEFAULT_GUARDRAILS, ...parsed };
  }

  private mapExperiment(row: any): MigrationExperiment {
    const guardrails = this.parseGuardrails(row.guardrails);
    const mode = (row.mode as ExperimentMode) || 'shadow';

    return {
      id: row.id,
      publisher_id: row.publisher_id,
      name: row.name,
      description: row.description,
      app_id: row.app_id,
      placement_id: row.placement_id,
      objective: row.objective,
      seed: row.seed,
      mirror_percent: row.mirror_percent,
      mode,
      status: row.status,
      activated_at: row.activated_at,
      paused_at: row.paused_at,
      completed_at: row.completed_at,
      guardrails,
      created_by: row.created_by,
      created_at: row.created_at,
      updated_at: row.updated_at,
      last_guardrail_check: row.last_guardrail_check,
    };
  }
}
