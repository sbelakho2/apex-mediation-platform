name: ML Export Validation

on:
  pull_request:
    paths:
      - 'ML/**'
      - 'models/fraud/**'
  workflow_dispatch:

jobs:
  validate-exports:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          cd ML
          pip install -r requirements-lock.txt
      
      - name: Download test artifacts
        run: |
          mkdir -p ML/test_data
          cat > ML/test_data/generate_test_data.py << 'EOF'
          import pandas as pd
          import numpy as np
          np.random.seed(42)
          df = pd.DataFrame({
              'feature_1': np.random.randn(1000),
              'feature_2': np.random.randn(1000),
              'feature_3': np.random.randn(1000),
              'label': np.random.randint(0, 2, 1000)
          })
          df.to_parquet('ML/test_data/test_features.parquet')
          EOF
          python ML/test_data/generate_test_data.py
      
      - name: Check for ONNX exports
        id: check_onnx
        run: |
          if [ -f "models/fraud/latest/fraud_model.onnx" ]; then
            echo "onnx_exists=true" >> $GITHUB_OUTPUT
          else
            echo "onnx_exists=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Validate ONNX export
        if: steps.check_onnx.outputs.onnx_exists == 'true'
        run: |
          cd ML
          python scripts/validate_export.py \
            --model-dir ../models/fraud/latest \
            --onnx-path ../models/fraud/latest/fraud_model.onnx \
            --test-features test_data/test_features.parquet \
            --output validation_results.json \
            --pr-auc-threshold 2.0 \
            --roc-auc-threshold 2.0 \
            --latency-threshold 5.0
      
      - name: Upload validation results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: export-validation-results
          path: ML/validation_results.json
          retention-days: 30
      
      - name: Comment PR with results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v8
        with:
          script: |
            const fs = require('fs');
            const resultsPath = 'ML/validation_results.json';
            if (!fs.existsSync(resultsPath)) {
              console.log('No validation results found');
              return;
            }
            
            const results = JSON.parse(fs.readFileSync(resultsPath, 'utf8'));
            const passed = results.overall_passed ? '✅' : '❌';
            
            let comment = `## ${passed} ML Export Validation\n\n`;
            
            for (const validation of results.validations) {
              const type = validation.onnx_path ? 'ONNX' : 'TorchScript';
              const metrics = validation.onnx_metrics || validation.pytorch_metrics;
              
              comment += `### ${type} Export\n\n`;
              comment += `| Metric | Training | Export | Delta |\n`;
              comment += `|--------|----------|--------|-------|\n`;
              comment += `| ROC-AUC | ${validation.training_metrics.roc_auc.toFixed(4)} | ${metrics.roc_auc.toFixed(4)} | ${validation.deltas.roc_auc_delta_pct.toFixed(2)}% |\n`;
              comment += `| PR-AUC | ${validation.training_metrics.pr_auc.toFixed(4)} | ${metrics.pr_auc.toFixed(4)} | ${validation.deltas.pr_auc_delta_pct.toFixed(2)}% |\n`;
              comment += `| p95 Latency | - | ${metrics.p95_latency_ms.toFixed(2)}ms | - |\n\n`;
              
              if (validation.failures && validation.failures.length > 0) {
                comment += `**Failures:**\n`;
                validation.failures.forEach(f => comment += `- ❌ ${f}\n`);
              } else {
                comment += `✅ All checks passed\n`;
              }
              comment += `\n`;
            }
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
